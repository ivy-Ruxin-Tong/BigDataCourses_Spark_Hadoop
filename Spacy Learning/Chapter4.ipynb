{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readme:\n",
    "\n",
    "This notebook documents what I learnt from https://course.spacy.io/en/. It contains notes/sample codes/sample problems from the course. \n",
    "\n",
    "Special thanks to the content creators and the presenter Ines\n",
    "\n",
    "This notebook is intended for self-study, not re-distributing contents. \n",
    "If you want to learn more about spaCy, please visit https://spacy.io/ or https://course.spacy.io/en/\n",
    "\n",
    "Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 4 : Training and Updating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How training words?\n",
    "    * Initialize the model weights randomly with nlp.begin_training\n",
    "    * Predict a few examples with the current weights by calling nlp.updates\n",
    "    * Compare prediction with true labels \n",
    "    * Calculate how to change weights to improve predictions\n",
    "    * Update weights slightly\n",
    "    * Go back to 2\n",
    "    \n",
    " Note :  Gradient : how to change the weight\n",
    " \n",
    "    * update an existing model : a few hundred to a few thousand examples\n",
    "    * train a new category : a few thousand to a million examples \n",
    "    * training to teach the model new labels, entity types or other classification schemes.\n",
    "    * spaCyâ€™s components are supervised models for text annotations, meaning they can only learn to reproduce examples, not guess new labels from raw text. Training does not help with discovering patterns in unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "\n",
    "with open(\"exercises/en/iphone.json\", encoding=\"utf8\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match \"iphone\" and \"x\"\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "\n",
    "# Token whose lowercase form matches \"iphone\" and a digit\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "# Add patterns to the matcher and check the result\n",
    "matcher.add(\"GADGET\", None, pattern1, pattern2)\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    print([doc[start:end] for match_id, start, end in matcher(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "\n",
    "with open(\"exercises/en/iphone.json\", encoding=\"utf8\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "matcher.add(\"GADGET\", None, pattern1, pattern2)\n",
    "\n",
    "TRAINING_DATA = []\n",
    "\n",
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    # Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    # Get (start character, end character, label) tuples of matches\n",
    "    entities = [(span.start_char, span.end_char, \"GADGET\") for span in spans]\n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc.text, {\"entities\": entities})\n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)\n",
    "\n",
    "print(*TRAINING_DATA, sep=\"\\n\")\n",
    "\n",
    "# ('How to preorder the iPhone X', {'entities': [(20, 28, 'GADGET')]})\n",
    "# ('iPhone X is coming', {'entities': [(0, 8, 'GADGET')]})\n",
    "# ('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 36, 'GADGET')]})\n",
    "# ('The iPhone 8 reviews are here', {'entities': [(4, 12, 'GADGET')]})\n",
    "# (\"iPhone 11 vs iPhone 8: What's the difference?\", {'entities': [(0, 9, 'GADGET'), (13, 21, 'GADGET')]})\n",
    "# ('I need a new phone! Any tips?', {'entities': []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How does training loop work?\n",
    "    * loop for a number of times\n",
    "    * shuffle the training data\n",
    "    * divide the data into batches\n",
    "    * update the model for each batch\n",
    "    * save the updated model\n",
    "* Best practice when training models\n",
    "    * Models can forget things\n",
    "        * mix in previously correct predictions\n",
    "                * website v.s. persons\n",
    "                * run existing spaCy model over data and extract all other relevant entities\n",
    "    * Models can't learn everything\n",
    "        * local context / surrounding words\n",
    "                * label schemes need to be consistent and not too specific (clothing is better than adult clothing/children clothing)\n",
    "                * use rules from generic to specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 1\n",
    "TRAINING_DATA = [\n",
    "    (\n",
    "        \"i went to amsterdem last year and the canals were beautiful\",\n",
    "        {\"entities\": [(10, 19, \"TOURIST_DESTINATION\")]},\n",
    "    ),\n",
    "    (\n",
    "        \"You should visit Paris once in your life, but the Eiffel Tower is kinda boring\",\n",
    "        {\"entities\": [(17, 22, \"TOURIST_DESTINATION\")]},\n",
    "    ),\n",
    "    (\"There's also a Paris in Arkansas, lol\", {\"entities\": []}),\n",
    "    (\n",
    "        \"Berlin is perfect for summer holiday: lots of parks, great nightlife, cheap beer!\",\n",
    "        {\"entities\": [(0, 6, \"TOURIST_DESTINATION\")]},\n",
    "    ),\n",
    "]\n",
    "\n",
    "# this is subjective, it will be better if we just name it as GPE or location, and use the rule-based system\n",
    "# to determine whether such an entity is tourist destination or not \n",
    "\n",
    "# so we should replace all \"TOURIST_DESTINATION\" with \"GPE\"\n",
    "# for the third doc, both paris and arkansas will have \"GPE\"\n",
    "#         \"There's also a Paris in Arkansas, lol\",\n",
    "#        {\"entities\": [(15, 20, \"GPE\"), (24, 32, \"GPE\")]},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
